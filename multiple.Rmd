---
bibliography: ref.bib
---

# (PART) Advanced usage {-}

# Using multiple references

```{r, echo=FALSE}
knitr::opts_chunk$set(error=FALSE, message=FALSE, warning=FALSE)
library(BiocStyle)
```

## Overview

In some cases, we may wish to use multiple references for annotation of a test dataset.
This yields a more comprehensive set of cell types that are not covered by any individual reference, 
especially when differences in the resolution are considered.
However, it is not trivial due to the presence of batch effects across references
(from differences in technology, experimental protocol or the biological system)
as well as differences in the annotation vocabulary between investigators.

Several strategies are available to combine inferences from multiple references:

- using reference-specific labels in a combined reference
- using harmonized labels in a combined reference
- combining scores across multiple references

This chapter discusses the various strengths and weaknesses of each strategy
and provides some practical demonstrations of each.
Here, we will use the HPCA and BlueprintEncode datasets as our references
and (yet another) PBMC dataset as the test.

```{r}
library(TENxPBMCData)
pbmc <- TENxPBMCData("pbmc8k")

library(SingleR)
hpca <- HumanPrimaryCellAtlasData(ensembl=TRUE)
bpe <- BlueprintEncodeData(ensembl=TRUE)
```

## Using reference-specific labels

In this strategy, each label is defined in the context of its reference dataset.
This means that a label - say, "B cell" - in reference dataset X is 
considered to be different from a "B cell" label in reference dataset Y.
Use of reference-specific labels is most appropriate if there are relevant biological differences between the references;
for example, if one reference is concerned with healthy tissue while the other reference considers diseased tissue,
it can be helpful to distinguish between the same cell type in different biological contexts.

We can easily implement this approach by combining the expression matrices together 
and pasting the reference name onto the corresponding character vector of labels. 
This modification ensures that the downstream `SingleR()` call
will treat each label-reference combination as a distinct entity.

```{r}
hpca2 <- hpca
hpca2$label.main <- paste0("HPCA.", hpca2$label.main)

bpe2 <- bpe
bpe2$label.main <- paste0("BPE.", bpe2$label.main)

shared <- intersect(rownames(hpca2), rownames(bpe2))
combined <- cbind(hpca2[shared,], bpe2[shared,])
```

It is then straightforward to perform annotation with the usual methods.

```{r}
com.res1 <- SingleR(pbmc, ref=combined, labels=combined$label.main, assay.type.test=1)
table(com.res1$labels)
```

However, this strategy identifies markers by directly comparing expression values across references,
meaning that the marker set is likely to contain genes responsible for uninteresting batch effects. 
This will increase noise during the calculation of the score in each reference, 
possibly leading to a loss of precision and a greater risk of technical variation dominating the classification results.
It also complicates interpretation as the cell type is always qualified by its reference of origin in the results.

## Using harmonized labels

This strategy also involves combining the reference datasets into a single matrix 
but the labels are now harmonized so that the same cell type is given the same label across references.
This allows feature selection methods to identify robust sets of label-specific markers 
that are more likely to generalize to other datasets.
It also simplifies interpretation as there is no need to worry about the reference of origin for each label.

Many of the `r Biocpkg("SingleR")` datasets already have their labels 
mapped to the [Cell Ontology](https://www.ebi.ac.uk/ols/ontologies/cl).
This provides a standard vocabulary to refer to the same cell type across multiple references.
To simplify interpretation, we set `cell.ont="nonna"` to remove all samples that could not be mapped to the ontology.

```{r}
hpca.ont <- HumanPrimaryCellAtlasData(ensembl=TRUE, cell.ont="nonna")
bpe.ont <- BlueprintEncodeData(ensembl=TRUE, cell.ont="nonna")

shared <- intersect(rownames(hpca.ont), rownames(bpe.ont))
combined.ont <- cbind(hpca.ont[shared,], bpe.ont[shared,])
combined.ont$source <- rep(c("HPCA", "BPE"), c(ncol(hpca.ont), ncol(bpe.ont)))

# Showing the top 10 most frequent terms:
tab <- table(combined.ont$label.ont, combined.ont$source)
head(tab[order(rowSums(tab), decreasing=TRUE),])
```

We perform annotation with `SingleR()` as previously described.
We set the `block=` argument in `de.args=` so as to indicate that DE genes should only be performed _within_ each reference,
and then the statistics merged _across_ references to identify the top markers.
This ensures that we do not directly compare expression values across references,
which reduces the susceptibility of the marker detection to batch effects.

```{r}
# TODO: add blocking mode for default marker detection.
com.res2 <- SingleR(pbmc, ref=combined.ont, labels=combined.ont$label.ont, 
    assay.type.test=1)
tab <- table(com.res2$labels)
head(sort(tab, decreasing=TRUE))
```

The most obvious problem with this approach is that it assumes that harmonized labels are available.
This is not always the case due to the use of different (often author-specific!) naming schemes,
which requires at best semi-automated mapping of the author-derived labels to the standard vocabulary.
The mapping process also runs the risk of discarding relevant information about the biological status
(e.g., activation status, disease condition) if there is no obvious counterpart for that state in the ontology.

## Comparing scores across references

The final strategy - and the default approach implemented in `SingleR()` -
involves performing classification separately within each reference, 
and then collating the results to choose the label with the highest score across references. 
This is a relatively expedient approach that avoids the need for explicit harmonization 
while also reducing exposure to reference-specific batch effects.

Use of this approach simply involves passing multiple objects to the `ref=` and `label=` argument in `SingleR()`.
This instructs the function to annotate the test dataset with each reference individually;
it then collects the best labels for each cell across all references and 
identifies the overall best-scoring label as the final prediction for that cell.
The second step requires a recomputation of scores across a subset of relevant markers
to ensure that these scores are comparable across references.

```{r}
com.res3 <- SingleR(test = pbmc, assay.type.test=1,
    ref = list(BPE=bpe, HPCA=hpca), 
    labels = list(bpe$label.main, hpca$label.main))
table(com.res3$labels)
```

The main appeal of this approach lies in the fact that it is based on the results of annotation with individual references.
This avoids batch effects from comparing expression values across references;
it reduces the need for any coordination in the label scheme between references;
and simultaneously provides the per-reference annotations in the results.
The last feature is particularly useful as it allows for more detailed diagnostics, troubleshooting and further analysis.

```{r}
head(com.res3$orig.results$BPE$labels)
head(com.res3$orig.results$HPCA$labels)
```

The main downside is that it is somewhat suboptimal if there are many reference-specific labels, 
as markers are not identified with the aim of distinguishing a label in one reference from another label in another reference.
The lack of harmonization in the labels also complicates interpretation of the results,
though this can be addressed in the same manner as described above (i.e., replacing `label.main` with `label.ont`).

## Session info {-}

```{r}
sessionInfo()
```
